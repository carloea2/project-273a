{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMaLxCbzrUAxzo/bW1o0d1q",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/carloea2/project-273a/blob/main/toe.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6885005d",
        "outputId": "b25c89c9-e45f-420e-96a5-be50900ebf0c"
      },
      "source": [
        "!git clone https://github.com/seongjinyoon/toe.git"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'toe' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XueA1LM-CH1v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git pull"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Ix3t5fMCBU2",
        "outputId": "7cddd9d4-462b-4864-e232-16de2beed4bb"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: not a git repository (or any of the parent directories): .git\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "71b040fb"
      },
      "source": [
        "First, let's import the necessary libraries."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch_geometric"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oV5K9dMVB2i5",
        "outputId": "950cf237-82e8-4d2c-e2a9-afd5e11c3305"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch_geometric\n",
            "  Downloading torch_geometric-2.7.0-py3-none-any.whl.metadata (63 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/63.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.7/63.7 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (3.13.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (2025.3.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (3.1.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (2.0.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (3.2.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (3.6.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (1.22.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch_geometric) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->torch_geometric) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->torch_geometric) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->torch_geometric) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->torch_geometric) (2025.10.5)\n",
            "Requirement already satisfied: typing-extensions>=4.2 in /usr/local/lib/python3.12/dist-packages (from aiosignal>=1.4.0->aiohttp->torch_geometric) (4.15.0)\n",
            "Downloading torch_geometric-2.7.0-py3-none-any.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m67.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch_geometric\n",
            "Successfully installed torch_geometric-2.7.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "27e9bdf2"
      },
      "source": [
        "import json\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GATConv, global_mean_pool\n",
        "from torch_geometric.data import Data, DataLoader\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "import os"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "73f1e337"
      },
      "source": [
        "Now, let's define the `OperatorGAT` class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e7ab34f0"
      },
      "source": [
        "class OperatorGAT(nn.Module):\n",
        "    \"\"\"\n",
        "    Graph Attention Network for learning operator embeddings.\n",
        "\n",
        "    Architecture:\n",
        "    - Input: Initial operator embeddings from nomic-embed-code\n",
        "    - GAT layers: Learn attention weights between connected operators\n",
        "    - Output: Refined operator embeddings\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, input_dim, hidden_dim=256, output_dim=128, num_heads=4, num_layers=3, dropout=0.3):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            input_dim: Dimension of input embeddings (from nomic-embed-code)\n",
        "            hidden_dim: Hidden dimension for GAT layers\n",
        "            output_dim: Final embedding dimension\n",
        "            num_heads: Number of attention heads per GAT layer\n",
        "            num_layers: Number of GAT layers\n",
        "            dropout: Dropout rate\n",
        "        \"\"\"\n",
        "        super(OperatorGAT, self).__init__()\n",
        "\n",
        "        self.num_layers = num_layers\n",
        "        self.dropout = dropout\n",
        "\n",
        "        # Input projection\n",
        "        self.input_proj = nn.Linear(input_dim, hidden_dim)\n",
        "\n",
        "        # GAT layers\n",
        "        self.gat_layers = nn.ModuleList()\n",
        "        for i in range(num_layers):\n",
        "            if i == 0:\n",
        "                # First layer\n",
        "                self.gat_layers.append(\n",
        "                    GATConv(hidden_dim, hidden_dim // num_heads, heads=num_heads, dropout=dropout)\n",
        "                )\n",
        "            elif i == num_layers - 1:\n",
        "                # Last layer - output single head\n",
        "                self.gat_layers.append(\n",
        "                    GATConv(hidden_dim, output_dim, heads=1, concat=False, dropout=dropout)\n",
        "                )\n",
        "            else:\n",
        "                # Middle layers\n",
        "                self.gat_layers.append(\n",
        "                    GATConv(hidden_dim, hidden_dim // num_heads, heads=num_heads, dropout=dropout)\n",
        "                )\n",
        "\n",
        "        # Layer normalization\n",
        "        self.layer_norms = nn.ModuleList([\n",
        "            nn.LayerNorm(hidden_dim if i < num_layers - 1 else output_dim)\n",
        "            for i in range(num_layers)\n",
        "        ])\n",
        "\n",
        "    def forward(self, x, edge_index, batch=None):\n",
        "        \"\"\"\n",
        "        Forward pass through GAT.\n",
        "\n",
        "        Args:\n",
        "            x: Node features [num_nodes, input_dim]\n",
        "            edge_index: Edge connectivity [2, num_edges]\n",
        "            batch: Batch assignment for nodes (for batched graphs)\n",
        "\n",
        "        Returns:\n",
        "            Node embeddings [num_nodes, output_dim]\n",
        "        \"\"\"\n",
        "        # Input projection\n",
        "        x = self.input_proj(x)\n",
        "        x = F.relu(x)\n",
        "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
        "\n",
        "        # GAT layers with residual connections\n",
        "        for i, (gat, norm) in enumerate(zip(self.gat_layers, self.layer_norms)):\n",
        "            x_residual = x if i < self.num_layers - 1 else None\n",
        "\n",
        "            # GAT layer\n",
        "            x = gat(x, edge_index)\n",
        "            x = norm(x)\n",
        "\n",
        "            # Apply activation and dropout (except last layer)\n",
        "            if i < self.num_layers - 1:\n",
        "                x = F.elu(x)\n",
        "                x = F.dropout(x, p=self.dropout, training=self.training)\n",
        "\n",
        "                # Residual connection\n",
        "                if x_residual is not None and x_residual.shape == x.shape:\n",
        "                    x = x + x_residual\n",
        "\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "09f539ac"
      },
      "source": [
        "Next, we define the `WorkflowGraphDataset` class to handle loading the workflow data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c0cea50c"
      },
      "source": [
        "class WorkflowGraphDataset:\n",
        "    \"\"\"Dataset for loading workflows as PyTorch Geometric graphs.\"\"\"\n",
        "\n",
        "    def __init__(self, workflow_dir, operator_embeddings_file):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            workflow_dir: Directory containing workflow JSON files\n",
        "            operator_embeddings_file: JSON file with operator embeddings\n",
        "        \"\"\"\n",
        "        self.workflow_dir = Path(workflow_dir)\n",
        "        self.workflow_files = list(self.workflow_dir.glob('*.json'))\n",
        "\n",
        "        # Load operator embeddings\n",
        "        print(f\"Loading operator embeddings from {operator_embeddings_file}...\")\n",
        "        with open(operator_embeddings_file, 'r') as f:\n",
        "            embeddings_data = json.load(f)\n",
        "\n",
        "        # Create operator type to embedding mapping\n",
        "        self.operator_type_to_embedding = {\n",
        "            op_type: np.array(data['embedding'], dtype=np.float32)\n",
        "            for op_type, data in embeddings_data.items()\n",
        "        }\n",
        "\n",
        "        # Check how many embeddings and embedding dimension\n",
        "        self.embedding_dim = len(next(iter(self.operator_type_to_embedding.values())))\n",
        "        print(f\"Loaded {len(self.operator_type_to_embedding)} operator types\")\n",
        "        print(f\"Embedding dimension: {self.embedding_dim}\")\n",
        "\n",
        "        # Create a mapping for unknown operators (use mean embedding)\n",
        "        all_embeddings = np.array(list(self.operator_type_to_embedding.values()))\n",
        "        self.unknown_embedding = np.mean(all_embeddings, axis=0)\n",
        "\n",
        "    def load_workflow_graph(self, workflow_file):\n",
        "        \"\"\"\n",
        "        Load a single workflow as a PyTorch Geometric graph.\n",
        "\n",
        "        Returns:\n",
        "            Data object with node features and edge indices\n",
        "        \"\"\"\n",
        "        with open(workflow_file, 'r') as f:\n",
        "            workflow = json.load(f)\n",
        "\n",
        "        operators = workflow.get('operators', [])\n",
        "        links = workflow.get('links', [])\n",
        "\n",
        "        if len(operators) == 0:\n",
        "            return None\n",
        "\n",
        "        # Create operator ID to index mapping\n",
        "        op_id_to_idx = {op['operatorID']: idx for idx, op in enumerate(operators)}\n",
        "\n",
        "        # Create node features (operator embeddings)\n",
        "        node_features = []\n",
        "        operator_types = []\n",
        "\n",
        "        for op in operators:\n",
        "            op_type = op.get('operatorType', 'Unknown')\n",
        "            operator_types.append(op_type)\n",
        "\n",
        "            # Get embedding for this operator type\n",
        "            embedding = self.operator_type_to_embedding.get(op_type, self.unknown_embedding)\n",
        "            node_features.append(embedding)\n",
        "\n",
        "        node_features = np.array(node_features, dtype=np.float32)\n",
        "\n",
        "        # Create edge index from links\n",
        "        edge_list = []\n",
        "        for link in links:\n",
        "            source_id = link['source']['operatorID']\n",
        "            target_id = link['target']['operatorID']\n",
        "\n",
        "            if source_id in op_id_to_idx and target_id in op_id_to_idx:\n",
        "                source_idx = op_id_to_idx[source_id]\n",
        "                target_idx = op_id_to_idx[target_id]\n",
        "                edge_list.append([source_idx, target_idx])\n",
        "\n",
        "        if len(edge_list) == 0:\n",
        "            # No edges - create self-loops for isolated nodes\n",
        "            edge_list = [[i, i] for i in range(len(operators))]\n",
        "\n",
        "        edge_index = np.array(edge_list, dtype=np.int64).T\n",
        "\n",
        "        # Convert to PyTorch tensors\n",
        "        x = torch.tensor(node_features, dtype=torch.float32)\n",
        "        edge_index = torch.tensor(edge_index, dtype=torch.long)\n",
        "\n",
        "        # Create Data object\n",
        "        data = Data(x=x, edge_index=edge_index)\n",
        "        data.operator_types = operator_types\n",
        "        data.workflow_file = str(workflow_file)\n",
        "\n",
        "        return data\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.workflow_files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        workflow_file = self.workflow_files[idx]\n",
        "        return self.load_workflow_graph(workflow_file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aec58f14"
      },
      "source": [
        "Here are the functions for the graph reconstruction loss and extracting operator embeddings."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e222eff5"
      },
      "source": [
        "def create_graph_reconstruction_loss(embeddings, edge_index, negative_samples=5):\n",
        "    \"\"\"\n",
        "    Graph reconstruction loss: predict edges from node embeddings.\n",
        "    Encourages connected operators to have similar embeddings.\n",
        "\n",
        "    Args:\n",
        "        embeddings: Node embeddings [num_nodes, embedding_dim]\n",
        "        edge_index: Edge connectivity [2, num_edges]\n",
        "        negative_samples: Number of negative samples per positive edge\n",
        "\n",
        "    Returns:\n",
        "        Binary cross-entropy loss\n",
        "    \"\"\"\n",
        "    # Positive edges\n",
        "    src_embed = embeddings[edge_index[0]]\n",
        "    dst_embed = embeddings[edge_index[1]]\n",
        "\n",
        "    # Compute similarity (dot product)\n",
        "    pos_scores = torch.sum(src_embed * dst_embed, dim=1)\n",
        "    pos_loss = -F.logsigmoid(pos_scores).mean()\n",
        "\n",
        "    # Negative sampling\n",
        "    num_nodes = embeddings.size(0)\n",
        "    num_edges = edge_index.size(1)\n",
        "\n",
        "    # Sample random negative edges\n",
        "    neg_src = torch.randint(0, num_nodes, (num_edges * negative_samples,), device=embeddings.device)\n",
        "    neg_dst = torch.randint(0, num_nodes, (num_edges * negative_samples,), device=embeddings.device)\n",
        "\n",
        "    neg_src_embed = embeddings[neg_src]\n",
        "    neg_dst_embed = embeddings[neg_dst]\n",
        "\n",
        "    neg_scores = torch.sum(neg_src_embed * neg_dst_embed, dim=1)\n",
        "    neg_loss = -F.logsigmoid(-neg_scores).mean()\n",
        "\n",
        "    return pos_loss + neg_loss\n",
        "\n",
        "\n",
        "def train_epoch(model, dataloader, optimizer, device):\n",
        "    \"\"\"Train for one epoch.\"\"\"\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    num_graphs = 0\n",
        "\n",
        "    for batch in tqdm(dataloader, desc=\"Training\"):\n",
        "        if batch is None:\n",
        "            continue\n",
        "\n",
        "        batch = batch.to(device)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        embeddings = model(batch.x, batch.edge_index, batch.batch)\n",
        "\n",
        "        # Compute loss (link prediction on the graph)\n",
        "        loss = create_graph_reconstruction_loss(embeddings, batch.edge_index)\n",
        "\n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        num_graphs += 1\n",
        "\n",
        "    return total_loss / max(num_graphs, 1)\n",
        "\n",
        "\n",
        "def extract_operator_embeddings(model, dataset, device):\n",
        "    \"\"\"\n",
        "    Extract final operator embeddings by aggregating across all workflows.\n",
        "\n",
        "    For each operator type, we average the embeddings learned across all\n",
        "    workflows where that operator appears.\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    # Dictionary to collect embeddings for each operator type\n",
        "    operator_embeddings = {}\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i in tqdm(range(len(dataset)), desc=\"Extracting embeddings\"):\n",
        "            data = dataset[i]\n",
        "            if data is None:\n",
        "                continue\n",
        "\n",
        "            data = data.to(device)\n",
        "\n",
        "            # Get embeddings for this workflow\n",
        "            embeddings = model(data.x, data.edge_index)\n",
        "            embeddings = embeddings.cpu().numpy()\n",
        "\n",
        "            # Aggregate by operator type\n",
        "            for op_type, embed in zip(data.operator_types, embeddings):\n",
        "                if op_type not in operator_embeddings:\n",
        "                    operator_embeddings[op_type] = []\n",
        "                operator_embeddings[op_type].append(embed)\n",
        "\n",
        "    # Average embeddings for each operator type\n",
        "    final_embeddings = {}\n",
        "    for op_type, embed_list in operator_embeddings.items():\n",
        "        final_embeddings[op_type] = {\n",
        "            'embedding': np.mean(embed_list, axis=0).tolist(),\n",
        "            'embedding_dim': len(embed_list[0]),\n",
        "            'num_occurrences': len(embed_list)\n",
        "        }\n",
        "\n",
        "    return final_embeddings"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b2e6a8e6"
      },
      "source": [
        "Finally, here is the main execution block to set up and train the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "77361055"
      },
      "source": [
        "def main():\n",
        "    \"\"\"Main training function.\"\"\"\n",
        "\n",
        "    # Configuration\n",
        "    WORKFLOW_DIR = 'workflows_selected'\n",
        "    OPERATOR_EMBEDDINGS_FILE = 'operator_embeddings2.json'  # Initial embeddings from nomic-embed-code\n",
        "    OUTPUT_FILE = 'operator_embeddings_gat.json'  # Final embeddings after GAT\n",
        "\n",
        "    # Hyperparameters\n",
        "    HIDDEN_DIM = 256\n",
        "    OUTPUT_DIM = 128\n",
        "    NUM_HEADS = 4\n",
        "    NUM_LAYERS = 3\n",
        "    DROPOUT = 0.3\n",
        "    BATCH_SIZE = 32\n",
        "    NUM_EPOCHS = 50\n",
        "    LEARNING_RATE = 0.001\n",
        "\n",
        "    # Device\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    print(f\"Using device: {device}\")\n",
        "\n",
        "    # Load dataset\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"Loading workflow dataset...\")\n",
        "    print(\"=\"*80)\n",
        "    dataset = WorkflowGraphDataset(WORKFLOW_DIR, OPERATOR_EMBEDDINGS_FILE)\n",
        "\n",
        "    # Filter out None graphs\n",
        "    valid_graphs = [dataset[i] for i in range(len(dataset)) if dataset[i] is not None]\n",
        "    print(f\"\\nLoaded {len(valid_graphs)} valid workflow graphs\")\n",
        "\n",
        "    # Create dataloader\n",
        "    dataloader = DataLoader(valid_graphs, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "    # Initialize model, optimizer, and scheduler (if needed)\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"Initializing model and optimizer...\")\n",
        "    print(\"=\"*80)\n",
        "    model = OperatorGAT(\n",
        "        input_dim=dataset.embedding_dim,\n",
        "        hidden_dim=HIDDEN_DIM,\n",
        "        output_dim=OUTPUT_DIM,\n",
        "        num_heads=NUM_HEADS,\n",
        "        num_layers=NUM_LAYERS,\n",
        "        dropout=DROPOUT\n",
        "    ).to(device)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "    # Training loop\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(f\"Starting training for {NUM_EPOCHS} epochs...\")\n",
        "    print(\"=\"*80)\n",
        "    for epoch in range(1, NUM_EPOCHS + 1):\n",
        "        loss = train_epoch(model, dataloader, optimizer, device)\n",
        "        print(f\"Epoch {epoch}/{NUM_EPOCHS}, Loss: {loss:.4f}\")\n",
        "\n",
        "    # Extract and save final embeddings\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"Extracting and saving final operator embeddings...\")\n",
        "    print(\"=\"*80)\n",
        "    final_embeddings = extract_operator_embeddings(model, dataset, device)\n",
        "\n",
        "    with open(OUTPUT_FILE, 'w') as f:\n",
        "        json.dump(final_embeddings, f, indent=4)\n",
        "\n",
        "    print(f\"\\nFinal operator embeddings saved to {OUTPUT_FILE}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9b23d850",
        "outputId": "3eda8c58-530a-42db-c9ec-3ecbd7d96baa"
      },
      "source": [
        "# Read the content of the file\n",
        "with open('/content/toe/train_gat_embeddings.py', 'r') as f:\n",
        "    file_content = f.read()\n",
        "\n",
        "# Print the content\n",
        "print(file_content)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\"\"\"\n",
            "Train Graph Attention Network (GAT) to learn operator embeddings that combine:\n",
            "1. Semantic information from code embeddings (nomic-embed-code)\n",
            "2. Structural information from workflow graphs\n",
            "\n",
            "This script:\n",
            "- Loads operator code embeddings as initial node features\n",
            "- Loads workflow graphs from JSON files\n",
            "- Trains a GAT to learn better embeddings by considering how operators are connected\n",
            "- Outputs final operator embeddings that capture both semantics and usage patterns\n",
            "\"\"\"\n",
            "\n",
            "import json\n",
            "import torch\n",
            "import torch.nn as nn\n",
            "import torch.nn.functional as F\n",
            "from torch_geometric.nn import GATConv, global_mean_pool\n",
            "from torch_geometric.data import Data, DataLoader\n",
            "import numpy as np\n",
            "from pathlib import Path\n",
            "from tqdm import tqdm\n",
            "import os\n",
            "\n",
            "\n",
            "class OperatorGAT(nn.Module):\n",
            "    \"\"\"\n",
            "    Graph Attention Network for learning operator embeddings.\n",
            "\n",
            "    Architecture:\n",
            "    - Input: Initial operator embeddings from nomic-embed-code\n",
            "    - GAT layers: Learn attention weights between connected operators\n",
            "    - Output: Refined operator embeddings\n",
            "    \"\"\"\n",
            "\n",
            "    def __init__(self, input_dim, hidden_dim=256, output_dim=128, num_heads=4, num_layers=3, dropout=0.3):\n",
            "        \"\"\"\n",
            "        Args:\n",
            "            input_dim: Dimension of input embeddings (from nomic-embed-code)\n",
            "            hidden_dim: Hidden dimension for GAT layers\n",
            "            output_dim: Final embedding dimension\n",
            "            num_heads: Number of attention heads per GAT layer\n",
            "            num_layers: Number of GAT layers\n",
            "            dropout: Dropout rate\n",
            "        \"\"\"\n",
            "        super(OperatorGAT, self).__init__()\n",
            "\n",
            "        self.num_layers = num_layers\n",
            "        self.dropout = dropout\n",
            "\n",
            "        # Input projection\n",
            "        self.input_proj = nn.Linear(input_dim, hidden_dim)\n",
            "\n",
            "        # GAT layers\n",
            "        self.gat_layers = nn.ModuleList()\n",
            "        for i in range(num_layers):\n",
            "            if i == 0:\n",
            "                # First layer\n",
            "                self.gat_layers.append(\n",
            "                    GATConv(hidden_dim, hidden_dim // num_heads, heads=num_heads, dropout=dropout)\n",
            "                )\n",
            "            elif i == num_layers - 1:\n",
            "                # Last layer - output single head\n",
            "                self.gat_layers.append(\n",
            "                    GATConv(hidden_dim, output_dim, heads=1, concat=False, dropout=dropout)\n",
            "                )\n",
            "            else:\n",
            "                # Middle layers\n",
            "                self.gat_layers.append(\n",
            "                    GATConv(hidden_dim, hidden_dim // num_heads, heads=num_heads, dropout=dropout)\n",
            "                )\n",
            "\n",
            "        # Layer normalization\n",
            "        self.layer_norms = nn.ModuleList([\n",
            "            nn.LayerNorm(hidden_dim if i < num_layers - 1 else output_dim)\n",
            "            for i in range(num_layers)\n",
            "        ])\n",
            "\n",
            "    def forward(self, x, edge_index, batch=None):\n",
            "        \"\"\"\n",
            "        Forward pass through GAT.\n",
            "\n",
            "        Args:\n",
            "            x: Node features [num_nodes, input_dim]\n",
            "            edge_index: Edge connectivity [2, num_edges]\n",
            "            batch: Batch assignment for nodes (for batched graphs)\n",
            "\n",
            "        Returns:\n",
            "            Node embeddings [num_nodes, output_dim]\n",
            "        \"\"\"\n",
            "        # Input projection\n",
            "        x = self.input_proj(x)\n",
            "        x = F.relu(x)\n",
            "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
            "\n",
            "        # GAT layers with residual connections\n",
            "        for i, (gat, norm) in enumerate(zip(self.gat_layers, self.layer_norms)):\n",
            "            x_residual = x if i < self.num_layers - 1 else None\n",
            "\n",
            "            # GAT layer\n",
            "            x = gat(x, edge_index)\n",
            "            x = norm(x)\n",
            "\n",
            "            # Apply activation and dropout (except last layer)\n",
            "            if i < self.num_layers - 1:\n",
            "                x = F.elu(x)\n",
            "                x = F.dropout(x, p=self.dropout, training=self.training)\n",
            "\n",
            "                # Residual connection\n",
            "                if x_residual is not None and x_residual.shape == x.shape:\n",
            "                    x = x + x_residual\n",
            "\n",
            "        return x\n",
            "\n",
            "\n",
            "class WorkflowGraphDataset:\n",
            "    \"\"\"Dataset for loading workflows as PyTorch Geometric graphs.\"\"\"\n",
            "\n",
            "    def __init__(self, workflow_dir, operator_embeddings_file):\n",
            "        \"\"\"\n",
            "        Args:\n",
            "            workflow_dir: Directory containing workflow JSON files\n",
            "            operator_embeddings_file: JSON file with operator embeddings\n",
            "        \"\"\"\n",
            "        self.workflow_dir = Path(workflow_dir)\n",
            "        self.workflow_files = list(self.workflow_dir.glob('*.json'))\n",
            "\n",
            "        # Load operator embeddings\n",
            "        print(f\"Loading operator embeddings from {operator_embeddings_file}...\")\n",
            "        with open(operator_embeddings_file, 'r') as f:\n",
            "            embeddings_data = json.load(f)\n",
            "\n",
            "        # Create operator type to embedding mapping\n",
            "        self.operator_type_to_embedding = {\n",
            "            op_type: np.array(data['embedding'], dtype=np.float32)\n",
            "            for op_type, data in embeddings_data.items()\n",
            "        }\n",
            "\n",
            "        # Check how many embeddings and embedding dimension\n",
            "        self.embedding_dim = len(next(iter(self.operator_type_to_embedding.values())))\n",
            "        print(f\"Loaded {len(self.operator_type_to_embedding)} operator types\")\n",
            "        print(f\"Embedding dimension: {self.embedding_dim}\")\n",
            "\n",
            "        # Create a mapping for unknown operators (use mean embedding)\n",
            "        all_embeddings = np.array(list(self.operator_type_to_embedding.values()))\n",
            "        self.unknown_embedding = np.mean(all_embeddings, axis=0)\n",
            "\n",
            "    def load_workflow_graph(self, workflow_file):\n",
            "        \"\"\"\n",
            "        Load a single workflow as a PyTorch Geometric graph.\n",
            "\n",
            "        Returns:\n",
            "            Data object with node features and edge indices\n",
            "        \"\"\"\n",
            "        with open(workflow_file, 'r') as f:\n",
            "            workflow = json.load(f)\n",
            "\n",
            "        operators = workflow.get('operators', [])\n",
            "        links = workflow.get('links', [])\n",
            "\n",
            "        if len(operators) == 0:\n",
            "            return None\n",
            "\n",
            "        # Create operator ID to index mapping\n",
            "        op_id_to_idx = {op['operatorID']: idx for idx, op in enumerate(operators)}\n",
            "\n",
            "        # Create node features (operator embeddings)\n",
            "        node_features = []\n",
            "        operator_types = []\n",
            "\n",
            "        for op in operators:\n",
            "            op_type = op.get('operatorType', 'Unknown')\n",
            "            operator_types.append(op_type)\n",
            "\n",
            "            # Get embedding for this operator type\n",
            "            embedding = self.operator_type_to_embedding.get(op_type, self.unknown_embedding)\n",
            "            node_features.append(embedding)\n",
            "\n",
            "        node_features = np.array(node_features, dtype=np.float32)\n",
            "\n",
            "        # Create edge index from links\n",
            "        edge_list = []\n",
            "        for link in links:\n",
            "            source_id = link['source']['operatorID']\n",
            "            target_id = link['target']['operatorID']\n",
            "\n",
            "            if source_id in op_id_to_idx and target_id in op_id_to_idx:\n",
            "                source_idx = op_id_to_idx[source_id]\n",
            "                target_idx = op_id_to_idx[target_id]\n",
            "                edge_list.append([source_idx, target_idx])\n",
            "\n",
            "        if len(edge_list) == 0:\n",
            "            # No edges - create self-loops for isolated nodes\n",
            "            edge_list = [[i, i] for i in range(len(operators))]\n",
            "\n",
            "        edge_index = np.array(edge_list, dtype=np.int64).T\n",
            "\n",
            "        # Convert to PyTorch tensors\n",
            "        x = torch.tensor(node_features, dtype=torch.float32)\n",
            "        edge_index = torch.tensor(edge_index, dtype=torch.long)\n",
            "\n",
            "        # Create Data object\n",
            "        data = Data(x=x, edge_index=edge_index)\n",
            "        data.operator_types = operator_types\n",
            "        data.workflow_file = str(workflow_file)\n",
            "\n",
            "        return data\n",
            "\n",
            "    def __len__(self):\n",
            "        return len(self.workflow_files)\n",
            "\n",
            "    def __getitem__(self, idx):\n",
            "        workflow_file = self.workflow_files[idx]\n",
            "        return self.load_workflow_graph(workflow_file)\n",
            "\n",
            "\n",
            "def create_graph_reconstruction_loss(embeddings, edge_index, negative_samples=5):\n",
            "    \"\"\"\n",
            "    Graph reconstruction loss: predict edges from node embeddings.\n",
            "    Encourages connected operators to have similar embeddings.\n",
            "\n",
            "    Args:\n",
            "        embeddings: Node embeddings [num_nodes, embedding_dim]\n",
            "        edge_index: Edge connectivity [2, num_edges]\n",
            "        negative_samples: Number of negative samples per positive edge\n",
            "\n",
            "    Returns:\n",
            "        Binary cross-entropy loss\n",
            "    \"\"\"\n",
            "    # Positive edges\n",
            "    src_embed = embeddings[edge_index[0]]\n",
            "    dst_embed = embeddings[edge_index[1]]\n",
            "\n",
            "    # Compute similarity (dot product)\n",
            "    pos_scores = torch.sum(src_embed * dst_embed, dim=1)\n",
            "    pos_loss = -F.logsigmoid(pos_scores).mean()\n",
            "\n",
            "    # Negative sampling\n",
            "    num_nodes = embeddings.size(0)\n",
            "    num_edges = edge_index.size(1)\n",
            "\n",
            "    # Sample random negative edges\n",
            "    neg_src = torch.randint(0, num_nodes, (num_edges * negative_samples,), device=embeddings.device)\n",
            "    neg_dst = torch.randint(0, num_nodes, (num_edges * negative_samples,), device=embeddings.device)\n",
            "\n",
            "    neg_src_embed = embeddings[neg_src]\n",
            "    neg_dst_embed = embeddings[neg_dst]\n",
            "\n",
            "    neg_scores = torch.sum(neg_src_embed * neg_dst_embed, dim=1)\n",
            "    neg_loss = -F.logsigmoid(-neg_scores).mean()\n",
            "\n",
            "    return pos_loss + neg_loss\n",
            "\n",
            "\n",
            "def train_epoch(model, dataloader, optimizer, device):\n",
            "    \"\"\"Train for one epoch.\"\"\"\n",
            "    model.train()\n",
            "    total_loss = 0\n",
            "    num_graphs = 0\n",
            "\n",
            "    for batch in tqdm(dataloader, desc=\"Training\"):\n",
            "        if batch is None:\n",
            "            continue\n",
            "\n",
            "        batch = batch.to(device)\n",
            "        optimizer.zero_grad()\n",
            "\n",
            "        # Forward pass\n",
            "        embeddings = model(batch.x, batch.edge_index, batch.batch)\n",
            "\n",
            "        # Compute loss (link prediction on the graph)\n",
            "        loss = create_graph_reconstruction_loss(embeddings, batch.edge_index)\n",
            "\n",
            "        # Backward pass\n",
            "        loss.backward()\n",
            "        optimizer.step()\n",
            "\n",
            "        total_loss += loss.item()\n",
            "        num_graphs += 1\n",
            "\n",
            "    return total_loss / max(num_graphs, 1)\n",
            "\n",
            "\n",
            "def extract_operator_embeddings(model, dataset, device):\n",
            "    \"\"\"\n",
            "    Extract final operator embeddings by aggregating across all workflows.\n",
            "\n",
            "    For each operator type, we average the embeddings learned across all\n",
            "    workflows where that operator appears.\n",
            "    \"\"\"\n",
            "    model.eval()\n",
            "\n",
            "    # Dictionary to collect embeddings for each operator type\n",
            "    operator_embeddings = {}\n",
            "\n",
            "    with torch.no_grad():\n",
            "        for i in tqdm(range(len(dataset)), desc=\"Extracting embeddings\"):\n",
            "            data = dataset[i]\n",
            "            if data is None:\n",
            "                continue\n",
            "\n",
            "            data = data.to(device)\n",
            "\n",
            "            # Get embeddings for this workflow\n",
            "            embeddings = model(data.x, data.edge_index)\n",
            "            embeddings = embeddings.cpu().numpy()\n",
            "\n",
            "            # Aggregate by operator type\n",
            "            for op_type, embed in zip(data.operator_types, embeddings):\n",
            "                if op_type not in operator_embeddings:\n",
            "                    operator_embeddings[op_type] = []\n",
            "                operator_embeddings[op_type].append(embed)\n",
            "\n",
            "    # Average embeddings for each operator type\n",
            "    final_embeddings = {}\n",
            "    for op_type, embed_list in operator_embeddings.items():\n",
            "        final_embeddings[op_type] = {\n",
            "            'embedding': np.mean(embed_list, axis=0).tolist(),\n",
            "            'embedding_dim': len(embed_list[0]),\n",
            "            'num_occurrences': len(embed_list)\n",
            "        }\n",
            "\n",
            "    return final_embeddings\n",
            "\n",
            "\n",
            "def main():\n",
            "    \"\"\"Main training function.\"\"\"\n",
            "\n",
            "    # Configuration\n",
            "    WORKFLOW_DIR = 'workflows_selected'\n",
            "    OPERATOR_EMBEDDINGS_FILE = 'operator_embeddings2.json'  # Initial embeddings from nomic-embed-code\n",
            "    OUTPUT_FILE = 'operator_embeddings_gat.json'  # Final embeddings after GAT\n",
            "\n",
            "    # Hyperparameters\n",
            "    HIDDEN_DIM = 256\n",
            "    OUTPUT_DIM = 128\n",
            "    NUM_HEADS = 4\n",
            "    NUM_LAYERS = 3\n",
            "    DROPOUT = 0.3\n",
            "    BATCH_SIZE = 32\n",
            "    NUM_EPOCHS = 50\n",
            "    LEARNING_RATE = 0.001\n",
            "\n",
            "    # Device\n",
            "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
            "    print(f\"Using device: {device}\")\n",
            "\n",
            "    # Load dataset\n",
            "    print(\"\\n\" + \"=\"*80)\n",
            "    print(\"Loading workflow dataset...\")\n",
            "    print(\"=\"*80)\n",
            "    dataset = WorkflowGraphDataset(WORKFLOW_DIR, OPERATOR_EMBEDDINGS_FILE)\n",
            "\n",
            "    # Filter out None graphs\n",
            "    valid_graphs = [dataset[i] for i in range(len(dataset)) if dataset[i] is not None]\n",
            "    print(f\"\\nLoaded {len(valid_graphs)} valid workflow graphs\")\n",
            "\n",
            "    # Create dataloader\n",
            "    dataloader = DataLoader(valid_graphs, batch_size=BATCH_SIZE, shuffle=True)\n",
            "\n",
            "    # Create model\n",
            "    print(\"\\n\" + \"=\"*80)\n",
            "    print(\"Creating GAT model...\")\n",
            "    print(\"=\"*80)\n",
            "    model = OperatorGAT(\n",
            "        input_dim=dataset.embedding_dim,\n",
            "        hidden_dim=HIDDEN_DIM,\n",
            "        output_dim=OUTPUT_DIM,\n",
            "        num_heads=NUM_HEADS,\n",
            "        num_layers=NUM_LAYERS,\n",
            "        dropout=DROPOUT\n",
            "    ).to(device)\n",
            "\n",
            "    print(f\"Model parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
            "\n",
            "    # Optimizer\n",
            "    optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=1e-5)\n",
            "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5)\n",
            "\n",
            "    # Training loop\n",
            "    print(\"\\n\" + \"=\"*80)\n",
            "    print(\"Training GAT...\")\n",
            "    print(\"=\"*80)\n",
            "\n",
            "    best_loss = float('inf')\n",
            "    for epoch in range(NUM_EPOCHS):\n",
            "        loss = train_epoch(model, dataloader, optimizer, device)\n",
            "        scheduler.step(loss)\n",
            "\n",
            "        print(f\"Epoch {epoch+1}/{NUM_EPOCHS} | Loss: {loss:.4f} | LR: {optimizer.param_groups[0]['lr']:.6f}\")\n",
            "\n",
            "        if loss < best_loss:\n",
            "            best_loss = loss\n",
            "            # Save best model\n",
            "            torch.save(model.state_dict(), 'best_gat_model.pt')\n",
            "\n",
            "    # Load best model\n",
            "    print(\"\\n\" + \"=\"*80)\n",
            "    print(\"Loading best model and extracting operator embeddings...\")\n",
            "    print(\"=\"*80)\n",
            "    model.load_state_dict(torch.load('best_gat_model.pt'))\n",
            "\n",
            "    # Extract final operator embeddings\n",
            "    final_embeddings = extract_operator_embeddings(model, dataset, device)\n",
            "\n",
            "    # Save embeddings\n",
            "    print(f\"\\nSaving final operator embeddings to {OUTPUT_FILE}...\")\n",
            "    with open(OUTPUT_FILE, 'w') as f:\n",
            "        json.dump(final_embeddings, f, indent=2)\n",
            "\n",
            "    print(f\"\\nExtracted embeddings for {len(final_embeddings)} operator types\")\n",
            "    print(\"\\n\" + \"=\"*80)\n",
            "    print(\"Training complete!\")\n",
            "    print(\"=\"*80)\n",
            "    print(f\"\\nOutputs:\")\n",
            "    print(f\"  - {OUTPUT_FILE}: Final operator embeddings (semantic + structural)\")\n",
            "    print(f\"  - best_gat_model.pt: Trained GAT model\")\n",
            "\n",
            "\n",
            "if __name__ == \"__main__\":\n",
            "    main()\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PNkvhtQNAVBV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}